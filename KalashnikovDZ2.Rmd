---
title: "Linear Regression"
author: "Stepan"
date: '25 ??????? 2020 ? '
output: word_document
---

```{r Download the data}
#Source files are here
setwd('C:/Users/Stepan/Desktop/6 курс/Машинное обучение/DZ2')
##Features scaling is included in the packages we will work with
#Download the files
d_train <- read.csv2('DATASET_train.csv', header = TRUE, encoding = 'UNICOD')
d_train <- d_train[,-1]

d_test <- read.csv2('DATASET_test.csv', header = TRUE, encoding = 'UNICOD')
d_test <- d_test[,-1]

```
#Висновок: окремо задані навчальна і тестова вибірки, видалені перші стовпчики з індексами об’єктів до кожної з підвибірок.

```{r model}
model_sr <- lm(LOAN_AMOUNT ~ CLIENT_TOGETHER_INCOME, d_train)
summary(model_sr)
```
#Висновок: обрана змінна незначуща, коефіцієнт детермінації 0,38.

```{r predicting}
p_sr <- predict(model_sr, d_test)
r2_sr <- 1-sum((d_train$LOAN_AMOUNT - predict(model_sr,
d_train))^2)/sum((d_train$LOAN_AMOUNT - mean(d_train$LOAN_AMOUNT))^2)
R2_sr <- cor(d_train$LOAN_AMOUNT, fitted(model_sr))^2 #simplier ex.
train_mse_sr <- sum((d_train$LOAN_AMOUNT-predict(model_sr,
d_train))^2)/length(d_train$LOAN_AMOUNT)
test_mse_sr <- sum((d_test$LOAN_AMOUNT-p_sr)^2)/length(p_sr)
r2_sr

R2_sr

train_mse_sr

test_mse_sr

```
#Висновок: вручну розраховані коефіцієнти детермінації. Значення середньоквадратичної похибки на навчальній вибірці – 205 067 756, на тестовій вибірці – 199 990 348, тобто перенавчання немає.

```{r Visualising}
library(ggplot2)
ggplot() + 
  geom_point(aes(d_train$CLIENT_TOGETHER_INCOME, d_train$LOAN_AMOUNT), colour = 'red') + geom_point(aes(d_test$CLIENT_TOGETHER_INCOME, d_test$LOAN_AMOUNT), colour = 'dark green') + 
  geom_line(aes(d_test$CLIENT_TOGETHER_INCOME, p_sr),colour = 'blue') + 
  ggtitle('LOAN_AMOUNT vs CLIENT_TOGETHER_INCOME') + 
  xlab('CLIENT_TOGETHER_INCOME') + 
  ylab('LOAN_AMOUNT')

```
#Висновок: на графіку червоним позначені точки навчальної вибірки, зеленим – точки тестової вибірки, синім – модельні значення..
```{r All factors}

model_mr <- lm(data = d_train, LOAN_AMOUNT ~ .)
summary(model_mr) 

```
#Висновок: змінні CLIENT_COUNTDEPENDENTS, CLIENT_ACTIVITYTYPE, LOAN_OUTSTANDINGLOANSCOUNT, DECADE, ZODIAC, ZODIAC_CHINA, CHANGE_WORK, REAL_ESTATE, INFORMATION_IN_BKI найменш значущі, коефіцієнт детермінації 0,855.
```{r Optimized model}
#as p-value, Pr(>|t|) of variable "type" is higher than significance level (5%), let's exclude this variable from the model
model_opt <- lm(data = d_train, LOAN_AMOUNT ~ LOAN_PRODUCT_TYPE + BRANCH_REGION + CLIENT_GENDER + CLIENT_TOTALEXPERIENCE + CLIENT_EDUCATION + CLIENT_TOGETHER_INCOME + LOAN_EXISTINGCUSTOMERFLAG + LOAN_OVERDUE_EXIST_FLAG + SCR_WORKPLACECONFIRMED + AGE + MATCH_OF_THE_REGISTRATION_PLACE_WITH_THE_ACTUAL_RESIDENCE + FAMILY_PHONE + CAR + PERCENT_IN_THE_LOAN_AMOUNT + DELAY) 
summary(model_opt)  
```
#Висновок: усі змінні значущі, коефіцієнт детермінації трохи зменшився – 0,836.
```{r Prediction Optimized model}
p_mr <- predict(model_opt, d_test)

train_mse_opt <- sum((d_train$LOAN_AMOUNT-predict(model_opt, d_train))^2)/length(d_train$LOAN_AMOUNT)
test_mse_opt <- sum((d_test$LOAN_AMOUNT-p_mr)^2)/length(p_mr)

train_mse_opt
test_mse_opt
```
#Висновок: значення середньоквадратичної помилки покращилися – на навчальній вибірці – 484 489 64, на тестовій вибірці – 451 199 52, тобто перенавчання немає.
```{r Visualising Optimized model}
ggplot() +
  geom_point(aes(d_train$CLIENT_TOGETHER_INCOME, d_train$LOAN_AMOUNT),colour = 'red') +
  geom_point(aes(d_test$CLIENT_TOGETHER_INCOME, d_test$LOAN_AMOUNT),colour = 'dark green') +
  geom_line(aes(d_test$CLIENT_TOGETHER_INCOME, p_mr),colour = 'blue') +
  ggtitle('LOAN_AMOUNT vs CLIENT_TOGETHER_INCOME') +
  xlab('CLIENT_TOGETHER_INCOME') +
  ylab('LOAN_AMOUNT')
```
#Висновок: на графіку червоним позначені точки навчальної вибірки, зеленим – точки тестової вибірки, синім – модельні значення.
```{r Polynomial Linear Regression}
d_train_poly <- d_train[,c('LOAN_AMOUNT', 'CLIENT_TOGETHER_INCOME')]
d_test_poly <- d_test[,c('LOAN_AMOUNT', 'CLIENT_TOGETHER_INCOME')]
d_train_poly$CLIENT_TOGETHER_INCOME2 <- d_train_poly$CLIENT_TOGETHER_INCOME^2
d_train_poly$CLIENT_TOGETHER_INCOME3 <- d_train_poly$CLIENT_TOGETHER_INCOME^3
d_test_poly$CLIENT_TOGETHER_INCOME2 <- d_test_poly$CLIENT_TOGETHER_INCOME^2
d_test_poly$CLIENT_TOGETHER_INCOME3 <- d_test_poly$CLIENT_TOGETHER_INCOME^3
model_pr <- lm(data = d_train_poly, LOAN_AMOUNT ~ CLIENT_TOGETHER_INCOME2 + CLIENT_TOGETHER_INCOME3)
summary(model_pr) 
```
#Висновок: додано змінні m2^2 та m2^3.
#Висновок: змінні m2^2 та m2^3 значущі, але коефіцієнт детермінації зменшився – 0,387.

```{r Predicting Polynomial Linear Regression}
p_pr <- predict(model_pr, d_test_poly)
train_mse_poly <- sum((d_train_poly$LOAN_AMOUNT-predict(model_pr,
d_train_poly))^2)/length(d_train_poly$LOAN_AMOUNT)
test_mse_poly <- sum((d_test_poly$LOAN_AMOUNT-p_pr)^2)/length(p_pr)
train_mse_poly
test_mse_poly

```
#Висновок: значення середньоквадратичної помилки трохи зросли на навчальній вибірці – 659 342 728, на тестовій вибірці – 635 313 813, тобто перенавчання немає.
```{r Visualising Polynomial Linear Regression}
ggplot() + 
  geom_point(aes(d_train_poly$CLIENT_TOGETHER_INCOME, d_train_poly$LOAN_AMOUNT), colour = 'red') + geom_point(aes(d_test_poly$CLIENT_TOGETHER_INCOME, d_test_poly$LOAN_AMOUNT), colour = 'dark green') + 
  geom_line(aes(d_test_poly$CLIENT_TOGETHER_INCOME, p_pr),colour = 'blue') + 
  ggtitle('LOAN_AMOUNT vs CLIENT_TOGETHER_INCOME') + 
  xlab('CLIENT_TOGETHER_INCOME') + 
  ylab('LOAN_AMOUNT')
  
```
#Висновок: на графіку червоним позначені точки навчальної вибірки, зеленим – точки тестової вибірки, синім – модельні значення.
```{r Saving results}
fit <- data.frame(p_sr, p_mr, p_pr)
write.csv2(fit, file = "LOAN_AMOUNT.csv")
```